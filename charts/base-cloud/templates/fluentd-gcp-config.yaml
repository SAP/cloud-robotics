{{ if eq .Values.stackdriver_logging "true" }}
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-gcp-sources
data:
  forward.input.conf: |-
    <source>
      @type forward
      bind 0.0.0.0
      port 24224
    </source>
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-gcp-main-config
data:
  google-fluentd.conf: |-
    @include config.d/*.conf
    <match **>
      @type relabel
      @label @OUTPUT
    </match>
    <label @OUTPUT>
      <filter **>
        @type grep
        <regexp>
          key source_type
          pattern /application/
        </regexp>
      </filter>

      <filter **>
        @type record_transformer
        enable_ruby true
        <record>
          # Rename the field 'log' to a more generic field 'message'. This way the
          # fluent-plugin-google-cloud knows to flatten the field as textPayload
          # instead of jsonPayload after extracting 'time', 'severity' and
          # 'stream' from the record.
          message ${record['log']}
          # If 'severity' is not set, assume stderr is ERROR and stdout is INFO.
          severity ${record['severity'] || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end}
          # Everthing except source_type application was removed by previous filter, so all entries are k8s_containers
          # Populate local_resource_id to facilitate filtering in stackdriver
          logging.googleapis.com/local_resource_id k8s_container.${record['kubernetes']['namespace_name']}.${record['kubernetes']['pod_name']}.${record['kubernetes']['container_name']}
        </record>
        remove_keys log
      </filter>

      # Add a unique insertId to each log entry that doesn't already have it.
      # This helps guarantee the order and prevent log duplication.
      <filter **>
        @type add_insert_ids
      </filter>

      <match **>
        @type google_cloud
        # There is no metadata service in this installation
        use_metadata_service false
        # Fake cluster name and location to make it work
        # Logs of all cloud and robot clusters will be assigned to cluster "cloud-robotics-fluentd" and could be separated by "cluster_identifier" later
        k8s_cluster_name cloud-robotics-fluentd
        k8s_cluster_location europe-west1-c
        # Try to detect JSON formatted log entries.
        detect_json true
        # Allow log entries from multiple containers to be sent in the same request.
        split_logs_by_tag false
        # Set the buffer type to file to improve the reliability and reduce the memory consumption
        buffer_type file
        buffer_path /var/log/fluentd-buffers/kubernetes.containers.buffer
        # Set queue_full action to block because we want to pause gracefully
        # in case of the off-the-limits load instead of throwing an exception
        buffer_queue_full_action block
        # Set the chunk limit conservatively to avoid exceeding the recommended
        # chunk size of 5MB per write request.
        buffer_chunk_limit 512k
        # Length limit of chunk queue. Together with `buffer_chunk_limit` affects disk space used.
        buffer_queue_limit 64
        # Never wait more than 5 seconds before flushing logs in the non-error case.
        flush_interval 5s
        # Never wait longer than 30 seconds between retries.
        max_retry_wait 30
        # Disable the limit on the number of retries (retry forever).
        disable_retry_limit
        # Use multiple threads for processing.
        num_threads 8
        use_grpc true
        # Skip timestamp adjustment as this is in a controlled environment with
        # known timestamp format. This helps with CPU usage.
        adjust_invalid_timestamps false
      </match>
    </label>
{{ end }}
