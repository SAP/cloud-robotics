domain: "...ondemand.com"
deploy_environment: "choose one of those GCP/Azure/AWS depending on kyma.cluster"
registry: "ghcr.io/sap/cloud-robotics"
robots: []
sap_btp_service_operator: "false"
tenant_gateway: kyma-system/kyma-gateway
tenant: "default"
tenant_domain: "tenant.local"
tenant_main_namespace: "t-tenant"
tenant_namespaces:
  - "t-tenant"

images:
  http_relay_server: "http-relay-server:latest"
  app_auth_proxy: "app-auth-proxy:latest"

# The default requests/limits are sufficient for small deployments with a few
# robots. For a large deployment with ~30 robots, you might need ~2CPU and
# ~12Gi mem.
# TODO(rodrigoq): can we reduce this by updating prometheus?
limits:
  cpu: "2000m"
  memory: "2Gi"

# The default persistent disk size. You need to adjust this defeping your fleet
# size and desired retention time.
#
# To compute the disk space required we used the formula in
# https://devops.stackexchange.com/questions/9298/how-to-calculate-disk-space-required-by-prometheus-v2-2
#
# retention_time_seconds = 90 * 24 * 60 * 60
# ingested_samples_per_second = avg(sum(rate(prometheus_tsdb_head_samples_appended_total[1d]))) = ~7000
# bytes_per_sample = avg(sum(rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[1d]) /
#                            rate(prometheus_tsdb_compaction_chunk_samples_sum[1d]))) = ~1.0
# needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample = ~72G
# Use a larger volume to account for future growth.
requests:
  storage: "200Gi"
retention:
  time: "90d"
  # Keep in sync with the disksize above and keep some headroom to avoid alerts.
  size: "180GB"

cookie_secret: ""
